<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Elnaz Balazadeh | Robotics & AI Researcher</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet" />
</head>
<body>

  <header class="hero">
    <div class="hero-content">
      <h1 class="name">Elnaz Balazadeh</h1>
      <h2 class="tagline">Robotics & AI Researcher</h2>
      <p class="intro">
        I'm passionate about building intelligent systems that bridge the gap between humans and machines. My work focuses on human-robot interaction, robotic manipulation, and real-world AI applications.
      </p>
      <div class="cta">
        <a href="#cv">View CV</a>
        <a href="#contact">Contact Me</a>
      </div>
    </div>
  </header>

  <hr class="section-divider" />

  <section class="research" id="research">
    <h2 class="section-title">Research & Publications</h2>
    <p class="interests">
      <strong>Research Interests:</strong><br>
      Robotic Manipulation Â· Human Demonstration Â· Reinforcement Learning Â· Deep Learning
    </p>

    <div class="pub-grid">
      <div class="pub-card">
        <h3>HUGGA: Human-like Grasp Generation...</h3>
        <p class="authors"><strong>E. Balazadeh</strong>, M. Tale Masouleh, A. Kalhor</p>
        <p class="venue">ICRoM 2023</p>
        <p class="abstract">We propose HUGGA, a deep learning approach to generate human-like grasp poses using MediaPipe data and approach vector encoding...</p>
        <a class="pub-link" href="https://ieeexplore.ieee.org/document/10412422" target="_blank">View on IEEE Xplore â†’</a>
      </div>

      <div class="pub-card">
        <h3>Mapping Human Grasping to 3-Finger Grippers</h3>
        <p class="authors">F. Naeinian, <strong>E. Balazadeh</strong>, M. Tale Masouleh</p>
        <p class="venue">ICEE 2024</p>
        <p class="abstract">This paper presents a predictive deep learning framework that maps human hand poses captured by MediaPipe to robotic 3-finger grasp configurations...</p>
        <a class="pub-link" href="https://ieeexplore.ieee.org/document/10668014" target="_blank">View on IEEE Xplore â†’</a>
      </div>

      <div class="pub-card">
        <h3>Autonomous UAV Indoor Navigation</h3>
        <p class="authors">H. Ghasemi, <strong>E. Balazadeh</strong>, S. Malekpour, A. Kalhor, M. Tale Masouleh</p>
        <p class="venue">ICRoM 2023</p>
        <p class="abstract">A neural-based approach for indoor UAV navigation using camera data and generative deep networks to predict safe flight paths in cluttered scenes...</p>
        <a class="pub-link" href="https://ieeexplore.ieee.org/document/10412578" target="_blank">View on IEEE Xplore â†’</a>
      </div>
    </div>
  </section>

  <hr class="section-divider" />

  <section class="ongoing-horizontal">
    <div class="ongoing-card">
      <div class="ongoing-left">
        <h4>ðŸ›  Ongoing Research</h4>
        <h2>PICK-CORD: A Multi-Sensor Dataset for Pick-and-Place</h2>
        <p class="ongoing-authors">B. Barazandeh, <strong>E. Balazadeh</strong>, H. Hosseini, M. Tale Masouleh</p>
      </div>
      <div class="ongoing-right">
        <p>We're actively building <strong>PICK-CORD</strong>, a new dataset to accelerate pick-and-place planning through multi-sensor human demonstrations. It includes synchronized RGB, depth, and IMU recordings from real manipulation tasks.</p>
        <p class="ongoing-status">Current status: <em>Annotation and trajectory extraction in progress...</em></p>
      </div>
    </div>
  </section>

</body>
</html>
